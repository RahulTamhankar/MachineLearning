{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormal heartbeat prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras[tensorflow] in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: packaging<22.0,>=0.21 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (21.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (1.0.2)\n",
      "Requirement already satisfied: tensorflow>=2.7.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from packaging<22.0,>=0.21->scikeras[tensorflow]) (3.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.20.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.25.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.10.0.2)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.5.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (58.0.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.12.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (14.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.20.1)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.46.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->scikeras[tensorflow]) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "# As I was not having tensorflow I tried to install the same\n",
    "!pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RAHULT~1\\AppData\\Local\\Temp/ipykernel_9728/1690820300.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Common imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_current_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"keras\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m     \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madvanced_activations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mserialize_keras_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocessingLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Image preprocessing layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m   \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m   \u001b[0mpd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from pandas.compat import (\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mnp_version_under1p18\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_np_version_under1p18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnp_array_datetime64_compat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# numpy versioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from pandas.util._decorators import (  # noqa\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\hashtable.pyx\u001b[0m in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\missing.pyx\u001b[0m in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtslibs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m from pandas._libs.tslibs.conversion import (\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mOutOfBoundsTimedelta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mlocalize_pydatetime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will predict the \"Target\" value in the data set:\n",
    "\n",
    "heartbeat = pd.read_csv(\"heartbeat_cleaned.csv\")\n",
    "heartbeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have dropped the target variable since we are trying to predict it\n",
    "y = heartbeat['Target']\n",
    "x = heartbeat.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the values of the train_y data set\n",
    "train_y[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartbeat['Target'].value_counts()/len(heartbeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 31ms/step - loss: 1.1521 - accuracy: 0.5695 - val_loss: 0.8353 - val_accuracy: 0.7048\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6805 - accuracy: 0.7758 - val_loss: 0.5928 - val_accuracy: 0.8049\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.8067 - val_loss: 0.5168 - val_accuracy: 0.8346\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5003 - accuracy: 0.8300 - val_loss: 0.4587 - val_accuracy: 0.8572\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.8518 - val_loss: 0.3993 - val_accuracy: 0.8698\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8823 - val_loss: 0.4101 - val_accuracy: 0.8903\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8991 - val_loss: 0.3367 - val_accuracy: 0.9070\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.9042 - val_loss: 0.5383 - val_accuracy: 0.8321\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8765 - val_loss: 0.3530 - val_accuracy: 0.8819\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8973 - val_loss: 0.3102 - val_accuracy: 0.9175\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.9088 - val_loss: 0.2816 - val_accuracy: 0.9188\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2789 - accuracy: 0.9185 - val_loss: 0.2927 - val_accuracy: 0.9116\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2681 - accuracy: 0.9216 - val_loss: 0.2842 - val_accuracy: 0.9125\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9225 - val_loss: 0.2539 - val_accuracy: 0.9196\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.9221 - val_loss: 0.2642 - val_accuracy: 0.9250\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2376 - accuracy: 0.9277 - val_loss: 0.2391 - val_accuracy: 0.9301\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2337 - accuracy: 0.9296 - val_loss: 0.2517 - val_accuracy: 0.9276\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.9313 - val_loss: 0.2460 - val_accuracy: 0.9238\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2349 - accuracy: 0.9295 - val_loss: 0.2290 - val_accuracy: 0.9296\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2093 - accuracy: 0.9359 - val_loss: 0.2392 - val_accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23919467628002167, 0.9258794188499451]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.24\n",
      "accuracy: 92.59%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(5, activation='sigmoid' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 14s 64ms/step - loss: 1.2063 - accuracy: 0.5793 - val_loss: 1.1172 - val_accuracy: 0.5884\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 1.1190 - accuracy: 0.5793 - val_loss: 1.0991 - val_accuracy: 0.5884\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 1.1045 - accuracy: 0.5793 - val_loss: 1.0852 - val_accuracy: 0.5884\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 1.0887 - accuracy: 0.5793 - val_loss: 1.0738 - val_accuracy: 0.5884\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0740 - accuracy: 0.5793 - val_loss: 1.0604 - val_accuracy: 0.5884\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 10s 58ms/step - loss: 1.0623 - accuracy: 0.5793 - val_loss: 1.0470 - val_accuracy: 0.5884\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 11s 60ms/step - loss: 1.0588 - accuracy: 0.5793 - val_loss: 1.0521 - val_accuracy: 0.5884\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0549 - accuracy: 0.5793 - val_loss: 1.0473 - val_accuracy: 0.5884\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 11s 63ms/step - loss: 1.0531 - accuracy: 0.5793 - val_loss: 1.0393 - val_accuracy: 0.5884\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 1.0525 - accuracy: 0.5793 - val_loss: 1.0338 - val_accuracy: 0.5884\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0511 - accuracy: 0.5793 - val_loss: 1.0323 - val_accuracy: 0.5884\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 1.0497 - accuracy: 0.5793 - val_loss: 1.0345 - val_accuracy: 0.5884\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 1.0497 - accuracy: 0.5793 - val_loss: 1.0296 - val_accuracy: 0.5884\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0481 - accuracy: 0.5793 - val_loss: 1.0418 - val_accuracy: 0.5884\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0485 - accuracy: 0.5894 - val_loss: 1.0291 - val_accuracy: 0.6235\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 1.0447 - accuracy: 0.6253 - val_loss: 1.0238 - val_accuracy: 0.6411\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 1.0426 - accuracy: 0.6287 - val_loss: 1.0376 - val_accuracy: 0.6298\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 1.0445 - accuracy: 0.6260 - val_loss: 1.0238 - val_accuracy: 0.6353\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0447 - accuracy: 0.6237 - val_loss: 1.0256 - val_accuracy: 0.6386\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0442 - accuracy: 0.6242 - val_loss: 1.0263 - val_accuracy: 0.6298\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0263375043869019, 0.6298157572746277]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.03\n",
      "accuracy: 62.98%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(5,input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 8s 31ms/step - loss: 1.1513 - accuracy: 0.5723 - val_loss: 1.0592 - val_accuracy: 0.5884\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 1.0626 - accuracy: 0.5739 - val_loss: 1.0331 - val_accuracy: 0.5884\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0112 - accuracy: 0.5996 - val_loss: 0.9521 - val_accuracy: 0.6382\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.9208 - accuracy: 0.6457 - val_loss: 0.8964 - val_accuracy: 0.6499\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.8054 - accuracy: 0.7094 - val_loss: 0.7825 - val_accuracy: 0.7341\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7171 - accuracy: 0.7674 - val_loss: 0.6434 - val_accuracy: 0.8078\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7851 - accuracy: 0.7414 - val_loss: 0.6984 - val_accuracy: 0.7864\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7101 - accuracy: 0.7719 - val_loss: 0.7821 - val_accuracy: 0.7316\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6838 - accuracy: 0.7766 - val_loss: 0.6631 - val_accuracy: 0.7776\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6666 - accuracy: 0.7755 - val_loss: 0.6411 - val_accuracy: 0.7814\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6695 - accuracy: 0.7782 - val_loss: 0.7054 - val_accuracy: 0.7613\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6467 - accuracy: 0.7791 - val_loss: 0.6447 - val_accuracy: 0.7889\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.6430 - accuracy: 0.7800 - val_loss: 0.7329 - val_accuracy: 0.7529\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7139 - accuracy: 0.7618 - val_loss: 0.7655 - val_accuracy: 0.7454\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.7100 - accuracy: 0.7690 - val_loss: 0.6245 - val_accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.6256 - accuracy: 0.8019 - val_loss: 0.8645 - val_accuracy: 0.6943\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6771 - accuracy: 0.7706 - val_loss: 0.6593 - val_accuracy: 0.7856\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6167 - accuracy: 0.8006 - val_loss: 0.7770 - val_accuracy: 0.7508\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6027 - accuracy: 0.8096 - val_loss: 0.5869 - val_accuracy: 0.8074\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.5797 - accuracy: 0.8205 - val_loss: 0.5720 - val_accuracy: 0.8245\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5719574093818665, 0.8245393633842468]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.57\n",
      "accuracy: 82.45%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(5, input_shape=[n_steps, n_inputs]),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 9s 37ms/step - loss: 1.1369 - accuracy: 0.5750 - val_loss: 1.0408 - val_accuracy: 0.6181\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0496 - accuracy: 0.6052 - val_loss: 1.0342 - val_accuracy: 0.5925\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.0347 - accuracy: 0.6043 - val_loss: 1.0735 - val_accuracy: 0.5745\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0245 - accuracy: 0.5976 - val_loss: 1.0134 - val_accuracy: 0.5925\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0183 - accuracy: 0.5998 - val_loss: 0.9983 - val_accuracy: 0.6164\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0081 - accuracy: 0.6039 - val_loss: 0.9972 - val_accuracy: 0.6223\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9972 - accuracy: 0.6192 - val_loss: 0.9954 - val_accuracy: 0.6512\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.9284 - accuracy: 0.6671 - val_loss: 0.9749 - val_accuracy: 0.6688\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.8620 - accuracy: 0.6874 - val_loss: 0.8470 - val_accuracy: 0.6993\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8164 - accuracy: 0.6945 - val_loss: 0.7766 - val_accuracy: 0.7165\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.7877 - accuracy: 0.7152 - val_loss: 0.7343 - val_accuracy: 0.7337\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.7386 - accuracy: 0.7538 - val_loss: 0.7570 - val_accuracy: 0.7609\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.6479 - accuracy: 0.8017 - val_loss: 0.5716 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.6043 - accuracy: 0.8134 - val_loss: 0.6156 - val_accuracy: 0.8220\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5797 - accuracy: 0.8209 - val_loss: 0.5280 - val_accuracy: 0.8425\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.5640 - accuracy: 0.8245 - val_loss: 0.5149 - val_accuracy: 0.8446\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5382 - accuracy: 0.8361 - val_loss: 0.6323 - val_accuracy: 0.8170\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.5305 - accuracy: 0.8345 - val_loss: 0.5137 - val_accuracy: 0.8384\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5123 - accuracy: 0.8405 - val_loss: 0.4867 - val_accuracy: 0.8492\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5051 - accuracy: 0.8430 - val_loss: 0.5190 - val_accuracy: 0.8262\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5190359950065613, 0.8262144327163696]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.52\n",
      "accuracy: 82.62%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(2, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(2, return_sequences=True),\n",
    "    keras.layers.GRU(2),\n",
    "    keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 25s 101ms/step - loss: -4.4257 - accuracy: 0.0564 - val_loss: -7.8710 - val_accuracy: 0.0549\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 17s 98ms/step - loss: -13.0934 - accuracy: 0.0564 - val_loss: -15.5882 - val_accuracy: 0.0549\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 18s 102ms/step - loss: -21.7605 - accuracy: 0.0564 - val_loss: -23.1215 - val_accuracy: 0.0549\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -30.2244 - accuracy: 0.0564 - val_loss: -30.6095 - val_accuracy: 0.0549\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -38.7439 - accuracy: 0.0564 - val_loss: -38.2967 - val_accuracy: 0.0549\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -47.4165 - accuracy: 0.0564 - val_loss: -45.7897 - val_accuracy: 0.0549\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 18s 101ms/step - loss: -55.7867 - accuracy: 0.0564 - val_loss: -53.2717 - val_accuracy: 0.0549\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 17s 98ms/step - loss: -64.0936 - accuracy: 0.0564 - val_loss: -60.8743 - val_accuracy: 0.0549\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 18s 100ms/step - loss: -72.7881 - accuracy: 0.0564 - val_loss: -68.3779 - val_accuracy: 0.0549\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 17s 99ms/step - loss: -81.0848 - accuracy: 0.0564 - val_loss: -75.7650 - val_accuracy: 0.0549\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 18s 100ms/step - loss: -89.7904 - accuracy: 0.0564 - val_loss: -83.4889 - val_accuracy: 0.0549\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -98.3611 - accuracy: 0.0564 - val_loss: -90.9655 - val_accuracy: 0.0549\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -106.7112 - accuracy: 0.0564 - val_loss: -98.5201 - val_accuracy: 0.0549\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 17s 96ms/step - loss: -115.2881 - accuracy: 0.0564 - val_loss: -106.2135 - val_accuracy: 0.0549\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 17s 95ms/step - loss: -123.8665 - accuracy: 0.0564 - val_loss: -113.8328 - val_accuracy: 0.0549\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 17s 99ms/step - loss: -132.6467 - accuracy: 0.0564 - val_loss: -121.5397 - val_accuracy: 0.0549\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 17s 95ms/step - loss: -141.1535 - accuracy: 0.0564 - val_loss: -128.9529 - val_accuracy: 0.0549\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 18s 101ms/step - loss: -149.5359 - accuracy: 0.0564 - val_loss: -136.4352 - val_accuracy: 0.0549\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 17s 99ms/step - loss: -158.0762 - accuracy: 0.0564 - val_loss: -143.9572 - val_accuracy: 0.0549\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 17s 98ms/step - loss: -166.4020 - accuracy: 0.0564 - val_loss: -151.4696 - val_accuracy: 0.0549\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.15)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-151.46958923339844, 0.05485762283205986]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -151.47\n",
      "accuracy: 5.49%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing the test values of each model you built"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As part of assignment, we tried to predict whether the measurement of Target column represents a normal heartbeat or other anomalies. https://usf.joinhandshake.com/career_fairs/26155?page=1&per_page=10&sort_direction=desc&sort_column=default#sessions\n",
    "I was able to produce the following test and train values accuracies for the above given model\n",
    "------------------------------------------------------------------------------------------------------\n",
    "                             Model                                                   Accuracy\n",
    " Cross-sectional shallow model using Keras (with only one hidden layer)\t              88.40%\n",
    " \n",
    " Cross-sectional deep model using Keras (with two or more hidden layers)              92.59%\n",
    " \n",
    " Sequential shallow LSTM Model (with only one LSTM layer)                             62.98%             \n",
    " \n",
    " Sequential deep LSTM Model (with only two LSTM layers)                               82.45%         \n",
    " \n",
    " Sequential shallow GRU Model (with only one GRU layer)                               82.62%                                                  \n",
    " Sequential deep GRU Model (with only two GRU layers)                                 5.49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? How does it compare to baseline?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As we can see the best performing model is Cross-sectional deep model using Keras as the accuracy of the model comes out to 92.59%.\n",
    "Baseline indicates how good the data is for the given problem or how well it is. It will also show what minimum results we can expect from further model improvement. My maximum baseline accuracy comes out to be around 58.20% so we can expect our model to give us minimum 58.20% accurate results. As we can see the accuracy of Cross-sectional deep model using Keras came out to be 92.59% which is much more than the baseline, this indicates that this model is the best predicting model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
