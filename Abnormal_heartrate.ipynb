{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The data is cleaned up. There are no unqueal length sequences. And, there is no zero padding. So, you shouldn't use any `Masking` layer (like I mentioned in the lecture). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras[tensorflow] in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (1.0.2)\n",
      "Requirement already satisfied: packaging<22.0,>=0.21 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (21.0)\n",
      "Requirement already satisfied: tensorflow>=2.7.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from packaging<22.0,>=0.21->scikeras[tensorflow]) (3.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (14.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.20.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.46.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.10.0.2)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.5.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (0.25.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorflow>=2.7.0->scikeras[tensorflow]) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.7.0->scikeras[tensorflow]) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.6.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rahul tamhankar\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.7.0->scikeras[tensorflow]) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "# As I was not having tensorflow I tried to install the same\n",
    "!pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"Target\" value in the data set:\n",
    "\n",
    "heartbeat = pd.read_csv(\"heartbeat_cleaned.csv\")\n",
    "heartbeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have dropped the target variable since we are trying to predict it\n",
    "y = heartbeat['Target']\n",
    "x = heartbeat.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720     0\n",
       "3822    0\n",
       "54      0\n",
       "7833    4\n",
       "2205    0\n",
       "       ..\n",
       "2006    0\n",
       "4076    0\n",
       "5384    2\n",
       "3767    0\n",
       "2733    0\n",
       "Name: Target, Length: 5542, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the values of the train_y data set\n",
    "train_y[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582035\n",
       "4    0.198995\n",
       "2    0.155402\n",
       "1    0.055905\n",
       "3    0.007663\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat['Target'].value_counts()/len(heartbeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 80, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 22ms/step - loss: 1.1176 - accuracy: 0.6179 - val_loss: 0.8627 - val_accuracy: 0.7098\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.7950 - accuracy: 0.7554 - val_loss: 0.7314 - val_accuracy: 0.7580\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7184 - accuracy: 0.7758 - val_loss: 0.6673 - val_accuracy: 0.7919\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.7902 - val_loss: 0.6335 - val_accuracy: 0.7973\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6353 - accuracy: 0.7895 - val_loss: 0.5866 - val_accuracy: 0.8199\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.8074 - val_loss: 0.5651 - val_accuracy: 0.8216\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.8175 - val_loss: 0.5332 - val_accuracy: 0.8162\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.8175 - val_loss: 0.5005 - val_accuracy: 0.8371\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.8272 - val_loss: 0.4869 - val_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4927 - accuracy: 0.8335 - val_loss: 0.4576 - val_accuracy: 0.8522\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.8431 - val_loss: 0.4417 - val_accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.8534 - val_loss: 0.4292 - val_accuracy: 0.8827\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8627 - val_loss: 0.4182 - val_accuracy: 0.8576\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8667 - val_loss: 0.4098 - val_accuracy: 0.8894\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8760 - val_loss: 0.4074 - val_accuracy: 0.8907\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8830 - val_loss: 0.3867 - val_accuracy: 0.8894\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8841 - val_loss: 0.3983 - val_accuracy: 0.8932\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8873 - val_loss: 0.3743 - val_accuracy: 0.8966\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8905 - val_loss: 0.3780 - val_accuracy: 0.8949\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8950 - val_loss: 0.3726 - val_accuracy: 0.8840\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3726443350315094, 0.8840033411979675]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.37\n",
      "accuracy: 88.40%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 31ms/step - loss: 1.1521 - accuracy: 0.5695 - val_loss: 0.8353 - val_accuracy: 0.7048\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.6805 - accuracy: 0.7758 - val_loss: 0.5928 - val_accuracy: 0.8049\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.8067 - val_loss: 0.5168 - val_accuracy: 0.8346\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5003 - accuracy: 0.8300 - val_loss: 0.4587 - val_accuracy: 0.8572\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.8518 - val_loss: 0.3993 - val_accuracy: 0.8698\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8823 - val_loss: 0.4101 - val_accuracy: 0.8903\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8991 - val_loss: 0.3367 - val_accuracy: 0.9070\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.9042 - val_loss: 0.5383 - val_accuracy: 0.8321\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8765 - val_loss: 0.3530 - val_accuracy: 0.8819\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8973 - val_loss: 0.3102 - val_accuracy: 0.9175\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.9088 - val_loss: 0.2816 - val_accuracy: 0.9188\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2789 - accuracy: 0.9185 - val_loss: 0.2927 - val_accuracy: 0.9116\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2681 - accuracy: 0.9216 - val_loss: 0.2842 - val_accuracy: 0.9125\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9225 - val_loss: 0.2539 - val_accuracy: 0.9196\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.9221 - val_loss: 0.2642 - val_accuracy: 0.9250\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2376 - accuracy: 0.9277 - val_loss: 0.2391 - val_accuracy: 0.9301\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2337 - accuracy: 0.9296 - val_loss: 0.2517 - val_accuracy: 0.9276\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.9313 - val_loss: 0.2460 - val_accuracy: 0.9238\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2349 - accuracy: 0.9295 - val_loss: 0.2290 - val_accuracy: 0.9296\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2093 - accuracy: 0.9359 - val_loss: 0.2392 - val_accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23919467628002167, 0.9258794188499451]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.24\n",
      "accuracy: 92.59%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(5, activation='sigmoid' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 14s 64ms/step - loss: 1.2063 - accuracy: 0.5793 - val_loss: 1.1172 - val_accuracy: 0.5884\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 1.1190 - accuracy: 0.5793 - val_loss: 1.0991 - val_accuracy: 0.5884\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 1.1045 - accuracy: 0.5793 - val_loss: 1.0852 - val_accuracy: 0.5884\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 1.0887 - accuracy: 0.5793 - val_loss: 1.0738 - val_accuracy: 0.5884\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0740 - accuracy: 0.5793 - val_loss: 1.0604 - val_accuracy: 0.5884\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 10s 58ms/step - loss: 1.0623 - accuracy: 0.5793 - val_loss: 1.0470 - val_accuracy: 0.5884\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 11s 60ms/step - loss: 1.0588 - accuracy: 0.5793 - val_loss: 1.0521 - val_accuracy: 0.5884\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0549 - accuracy: 0.5793 - val_loss: 1.0473 - val_accuracy: 0.5884\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 11s 63ms/step - loss: 1.0531 - accuracy: 0.5793 - val_loss: 1.0393 - val_accuracy: 0.5884\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 1.0525 - accuracy: 0.5793 - val_loss: 1.0338 - val_accuracy: 0.5884\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0511 - accuracy: 0.5793 - val_loss: 1.0323 - val_accuracy: 0.5884\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 10s 60ms/step - loss: 1.0497 - accuracy: 0.5793 - val_loss: 1.0345 - val_accuracy: 0.5884\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 1.0497 - accuracy: 0.5793 - val_loss: 1.0296 - val_accuracy: 0.5884\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0481 - accuracy: 0.5793 - val_loss: 1.0418 - val_accuracy: 0.5884\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0485 - accuracy: 0.5894 - val_loss: 1.0291 - val_accuracy: 0.6235\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 10s 55ms/step - loss: 1.0447 - accuracy: 0.6253 - val_loss: 1.0238 - val_accuracy: 0.6411\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 1.0426 - accuracy: 0.6287 - val_loss: 1.0376 - val_accuracy: 0.6298\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 1.0445 - accuracy: 0.6260 - val_loss: 1.0238 - val_accuracy: 0.6353\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0447 - accuracy: 0.6237 - val_loss: 1.0256 - val_accuracy: 0.6386\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 1.0442 - accuracy: 0.6242 - val_loss: 1.0263 - val_accuracy: 0.6298\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0263375043869019, 0.6298157572746277]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.03\n",
      "accuracy: 62.98%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(5,input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 8s 31ms/step - loss: 1.1513 - accuracy: 0.5723 - val_loss: 1.0592 - val_accuracy: 0.5884\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 1.0626 - accuracy: 0.5739 - val_loss: 1.0331 - val_accuracy: 0.5884\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0112 - accuracy: 0.5996 - val_loss: 0.9521 - val_accuracy: 0.6382\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.9208 - accuracy: 0.6457 - val_loss: 0.8964 - val_accuracy: 0.6499\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.8054 - accuracy: 0.7094 - val_loss: 0.7825 - val_accuracy: 0.7341\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7171 - accuracy: 0.7674 - val_loss: 0.6434 - val_accuracy: 0.8078\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7851 - accuracy: 0.7414 - val_loss: 0.6984 - val_accuracy: 0.7864\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7101 - accuracy: 0.7719 - val_loss: 0.7821 - val_accuracy: 0.7316\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6838 - accuracy: 0.7766 - val_loss: 0.6631 - val_accuracy: 0.7776\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6666 - accuracy: 0.7755 - val_loss: 0.6411 - val_accuracy: 0.7814\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6695 - accuracy: 0.7782 - val_loss: 0.7054 - val_accuracy: 0.7613\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6467 - accuracy: 0.7791 - val_loss: 0.6447 - val_accuracy: 0.7889\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.6430 - accuracy: 0.7800 - val_loss: 0.7329 - val_accuracy: 0.7529\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.7139 - accuracy: 0.7618 - val_loss: 0.7655 - val_accuracy: 0.7454\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.7100 - accuracy: 0.7690 - val_loss: 0.6245 - val_accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.6256 - accuracy: 0.8019 - val_loss: 0.8645 - val_accuracy: 0.6943\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6771 - accuracy: 0.7706 - val_loss: 0.6593 - val_accuracy: 0.7856\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6167 - accuracy: 0.8006 - val_loss: 0.7770 - val_accuracy: 0.7508\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.6027 - accuracy: 0.8096 - val_loss: 0.5869 - val_accuracy: 0.8074\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.5797 - accuracy: 0.8205 - val_loss: 0.5720 - val_accuracy: 0.8245\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5719574093818665, 0.8245393633842468]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.57\n",
      "accuracy: 82.45%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(5, input_shape=[n_steps, n_inputs]),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 9s 37ms/step - loss: 1.1369 - accuracy: 0.5750 - val_loss: 1.0408 - val_accuracy: 0.6181\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0496 - accuracy: 0.6052 - val_loss: 1.0342 - val_accuracy: 0.5925\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 1.0347 - accuracy: 0.6043 - val_loss: 1.0735 - val_accuracy: 0.5745\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0245 - accuracy: 0.5976 - val_loss: 1.0134 - val_accuracy: 0.5925\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0183 - accuracy: 0.5998 - val_loss: 0.9983 - val_accuracy: 0.6164\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 1.0081 - accuracy: 0.6039 - val_loss: 0.9972 - val_accuracy: 0.6223\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.9972 - accuracy: 0.6192 - val_loss: 0.9954 - val_accuracy: 0.6512\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 6s 33ms/step - loss: 0.9284 - accuracy: 0.6671 - val_loss: 0.9749 - val_accuracy: 0.6688\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.8620 - accuracy: 0.6874 - val_loss: 0.8470 - val_accuracy: 0.6993\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.8164 - accuracy: 0.6945 - val_loss: 0.7766 - val_accuracy: 0.7165\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.7877 - accuracy: 0.7152 - val_loss: 0.7343 - val_accuracy: 0.7337\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.7386 - accuracy: 0.7538 - val_loss: 0.7570 - val_accuracy: 0.7609\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.6479 - accuracy: 0.8017 - val_loss: 0.5716 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.6043 - accuracy: 0.8134 - val_loss: 0.6156 - val_accuracy: 0.8220\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5797 - accuracy: 0.8209 - val_loss: 0.5280 - val_accuracy: 0.8425\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.5640 - accuracy: 0.8245 - val_loss: 0.5149 - val_accuracy: 0.8446\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5382 - accuracy: 0.8361 - val_loss: 0.6323 - val_accuracy: 0.8170\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.5305 - accuracy: 0.8345 - val_loss: 0.5137 - val_accuracy: 0.8384\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5123 - accuracy: 0.8405 - val_loss: 0.4867 - val_accuracy: 0.8492\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 6s 35ms/step - loss: 0.5051 - accuracy: 0.8430 - val_loss: 0.5190 - val_accuracy: 0.8262\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5190359950065613, 0.8262144327163696]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.52\n",
      "accuracy: 82.62%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(2, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(2, return_sequences=True),\n",
    "    keras.layers.GRU(2),\n",
    "    keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 25s 101ms/step - loss: -4.4257 - accuracy: 0.0564 - val_loss: -7.8710 - val_accuracy: 0.0549\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 17s 98ms/step - loss: -13.0934 - accuracy: 0.0564 - val_loss: -15.5882 - val_accuracy: 0.0549\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 18s 102ms/step - loss: -21.7605 - accuracy: 0.0564 - val_loss: -23.1215 - val_accuracy: 0.0549\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -30.2244 - accuracy: 0.0564 - val_loss: -30.6095 - val_accuracy: 0.0549\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -38.7439 - accuracy: 0.0564 - val_loss: -38.2967 - val_accuracy: 0.0549\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -47.4165 - accuracy: 0.0564 - val_loss: -45.7897 - val_accuracy: 0.0549\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 18s 101ms/step - loss: -55.7867 - accuracy: 0.0564 - val_loss: -53.2717 - val_accuracy: 0.0549\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 17s 98ms/step - loss: -64.0936 - accuracy: 0.0564 - val_loss: -60.8743 - val_accuracy: 0.0549\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 18s 100ms/step - loss: -72.7881 - accuracy: 0.0564 - val_loss: -68.3779 - val_accuracy: 0.0549\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 17s 99ms/step - loss: -81.0848 - accuracy: 0.0564 - val_loss: -75.7650 - val_accuracy: 0.0549\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 18s 100ms/step - loss: -89.7904 - accuracy: 0.0564 - val_loss: -83.4889 - val_accuracy: 0.0549\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -98.3611 - accuracy: 0.0564 - val_loss: -90.9655 - val_accuracy: 0.0549\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: -106.7112 - accuracy: 0.0564 - val_loss: -98.5201 - val_accuracy: 0.0549\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 17s 96ms/step - loss: -115.2881 - accuracy: 0.0564 - val_loss: -106.2135 - val_accuracy: 0.0549\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 17s 95ms/step - loss: -123.8665 - accuracy: 0.0564 - val_loss: -113.8328 - val_accuracy: 0.0549\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 17s 99ms/step - loss: -132.6467 - accuracy: 0.0564 - val_loss: -121.5397 - val_accuracy: 0.0549\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 17s 95ms/step - loss: -141.1535 - accuracy: 0.0564 - val_loss: -128.9529 - val_accuracy: 0.0549\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 18s 101ms/step - loss: -149.5359 - accuracy: 0.0564 - val_loss: -136.4352 - val_accuracy: 0.0549\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 17s 99ms/step - loss: -158.0762 - accuracy: 0.0564 - val_loss: -143.9572 - val_accuracy: 0.0549\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 17s 98ms/step - loss: -166.4020 - accuracy: 0.0564 - val_loss: -151.4696 - val_accuracy: 0.0549\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.15)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-151.46958923339844, 0.05485762283205986]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -151.47\n",
      "accuracy: 5.49%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As part of assignment, we tried to predict whether the measurement of Target column represents a normal heartbeat or other anomalies. https://usf.joinhandshake.com/career_fairs/26155?page=1&per_page=10&sort_direction=desc&sort_column=default#sessions\n",
    "I was able to produce the following test and train values accuracies for the above given model\n",
    "------------------------------------------------------------------------------------------------------\n",
    "                             Model                                                   Accuracy\n",
    " Cross-sectional shallow model using Keras (with only one hidden layer)\t              88.40%\n",
    " \n",
    " Cross-sectional deep model using Keras (with two or more hidden layers)              92.59%\n",
    " \n",
    " Sequential shallow LSTM Model (with only one LSTM layer)                             62.98%             \n",
    " \n",
    " Sequential deep LSTM Model (with only two LSTM layers)                               82.45%         \n",
    " \n",
    " Sequential shallow GRU Model (with only one GRU layer)                               82.62%                                                  \n",
    " Sequential deep GRU Model (with only two GRU layers)                                 5.49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) \n",
    "## How does it compare to baseline? (0.5 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As we can see the best performing model is Cross-sectional deep model using Keras as the accuracy of the model comes out to 92.59%.\n",
    "Baseline indicates how good the data is for the given problem or how well it is. It will also show what minimum results we can expect from further model improvement. My maximum baseline accuracy comes out to be around 58.20% so we can expect our model to give us minimum 58.20% accurate results. As we can see the accuracy of Cross-sectional deep model using Keras came out to be 92.59% which is much more than the baseline, this indicates that this model is the best predicting model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
